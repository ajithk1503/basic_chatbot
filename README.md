## basic_chatbot
## Basic Chatbot using langchain and llama3.2:1b

This project is a simple chatbot built as part of a learning journey to understand how LangChain, LangServe, and FastAPI can work together to create powerful language-based applications. The chatbot uses the lightweight llama3.2:1b model via OllamaLLM to generate responses, making it easy to run locally without heavy infrastructure. Through this project, I explored how to define dynamic prompts using ChatPromptTemplate from LangChain, and how to serve those prompts using FastAPI. LangServe played a key role in exposing LangChain chains as API endpoints effortlessly, allowing me to build and test routes like /essay and /poem with minimal setup. Overall, this was a hands-on way to get familiar with modern tools for deploying LLM-powered services.

# To Run :
<li> install llama3.2:1b model</li>
<li> python app.py in one terminal </li>
<li> streamlit run client.py in other terminal </li>
